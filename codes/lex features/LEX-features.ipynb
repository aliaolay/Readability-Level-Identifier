{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts for Lexical Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import POS Tagger & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "\n",
    "# input local path to java.exe\n",
    "java_path = \"/usr/bin/java\" \n",
    "os.environ[\"JAVAHOME\"] = java_path\n",
    "\n",
    "#path to POS tagger jar\n",
    "jar_path = '/Users/jerseydayao/Desktop/hckrwmn/repositories/Readability-Level-Identifier'\n",
    "os.chdir(jar_path)\n",
    "jar =  jar_path + \"/stanford-postagger.jar\"\n",
    "\n",
    "# path to POS tagger model\n",
    "model_path = jar_path +\"/POSTagger/\"\n",
    "model = model_path + \"filipino-left5words-owlqn2-distsim-pref6-inf2.tagger\"\n",
    "\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text input and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text input\n",
    "text = \"nagsimula ang lahat sa masukal na bakuran ni aling salvacion.\"\n",
    "\n",
    "#tokenize text input\n",
    "words = nltk.word_tokenize(text)\n",
    "temp_words = [word for word in words if word.isalnum()] # removes punctuation marks\n",
    "\n",
    "#tag tokenized words\n",
    "tagged_words = pos_tagger.tag(temp_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun-Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nouns:  2\n",
      "Total number of tokens:  10\n",
      "Noun-Token Ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "# NOUN COUNT\n",
    "noun_count = 0\n",
    "for word, tag in tagged_words:\n",
    "    tag = tag.split('|')[-1] #removes word before |\n",
    "    if tag.startswith('NN'):\n",
    "        noun_count += 1\n",
    "        \n",
    "print(\"Number of nouns: \", noun_count)\n",
    "\n",
    "# NOUN TOKEN RATIO\n",
    "# = noun_count/total_token_count\n",
    "total_token_count = len(temp_words)\n",
    "noun_token_ratio = noun_count/total_token_count\n",
    "\n",
    "print(\"Total number of tokens: \", total_token_count)\n",
    "print(\"Noun-Token Ratio: \", noun_token_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb-Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERB COUNT\n",
    "verb_count = 0\n",
    "for word, tag in tagged_words:\n",
    "    tag = tag.split('|')[-1] #removes word before |\n",
    "    if tag.startswith('VB'):\n",
    "        verb_count += 1\n",
    "        \n",
    "print(\"Number of verbs: \", verb_count)\n",
    "\n",
    "# VERB TOKEN RATIO\n",
    "# = verb_count/total_token_count\n",
    "total_token_count = len(temp_words)\n",
    "verb_token_ratio = verb_count/total_token_count\n",
    "\n",
    "print(\"Total number of tokens: \", total_token_count)\n",
    "print(\"Noun-Token Ratio: \", verb_token_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type-Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique lexical categories\n",
    "unique_categories = set()\n",
    "for _, tag in tagged_words:\n",
    "    tag = tag.split('|')[-1] #removes word before |\n",
    "    if len(tag) >= 2:  # make sure the tag is not empty\n",
    "        category = tag[:2]  # extract the first two letters\n",
    "        unique_categories.add(category)\n",
    "\n",
    "print(\"Unique Categories:\", unique_categories)\n",
    "\n",
    "#NUMBER OF UNIQUE CATEGORIES\n",
    "num_categories = len(unique_categories)\n",
    "print(\"Number of Unique Categories:\", num_categories)\n",
    "\n",
    "# TOTAL NUM OF TOKENS\n",
    "total_token_count = len(temp_words)\n",
    "\n",
    "# TYPE TOKEN RATIO\n",
    "ttr = num_categories/total_token_count\n",
    "print(\"Type-Token Ratio: \", ttr)\n",
    "\n",
    "#ROOT TTR\n",
    "root_ttr = num_categories/math.sqrt(total_token_count)\n",
    "print(\"Root Type-Token Ratio: \", root_ttr)\n",
    "\n",
    "#CORR TTR\n",
    "corr_ttr = num_categories/math.sqrt(2*total_token_count)\n",
    "print(\"Corrected Type-Token Ratio: \", corr_ttr)\n",
    "\n",
    "#BILOGARITHMIC TTR\n",
    "log_ttr = math.log(num_categories)/math.log(total_token_count)\n",
    "print(\"Bilogarithmic Type-Token Ratio: \", log_ttr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF LEXICAL WORDS\n",
    "# count number of nouns, verbs, adjectives, and adverbs\n",
    "num_lexwords = 0\n",
    "for word, tag in tagged_words:\n",
    "    tag = tag.split('|')[-1] #removes word before |\n",
    "    if tag.startswith('NN') or tag.startswith('VB') or tag.startswith('JJ') or tag.startswith('RB'):\n",
    "        num_lexwords += 1\n",
    "        \n",
    "print(\"Number of lexical words: \", num_lexwords)\n",
    "\n",
    "# LEXICAL DENSITY\n",
    "# = lex_density/total_token_count\n",
    "total_token_count = len(temp_words)\n",
    "lex_density = num_lexwords/total_token_count\n",
    "\n",
    "print(\"Total number of tokens: \", total_token_count)\n",
    "print(\"Lexical Density: \", lex_density)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
