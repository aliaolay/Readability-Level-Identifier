{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiled Scripts for Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> _Click 'Run All' to extract the text features of a text file._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "import syllables\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/clean-txt/\"      # gets path to 'clean-txt' directory\n",
    "filename = input(\"Input filename (must be in the clean-txt folder): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words:  973\n"
     ]
    }
   ],
   "source": [
    "file = open(path + filename, \"rt\")\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print(\"Number of Words: \", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  85\n"
     ]
    }
   ],
   "source": [
    "folder = nltk.data.find(path)\n",
    "corpusReader = nltk.corpus.PlaintextCorpusReader(folder, filename)\n",
    "\n",
    "print(\"Number of Sentences: \", len(corpusReader.sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Length:  5.216380182002022 letters\n"
     ]
    }
   ],
   "source": [
    "with open(path + \"/\" + filename, 'r') as file:\n",
    "    word_length = [len(word) for line in file for word in line.rstrip().split(\" \")]\n",
    "    word_avg = sum(word_length)/len(word_length)\n",
    "    \n",
    "print(\"Average Word Length: \", word_avg, \"letters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length:  13.823529411764707 words\n"
     ]
    }
   ],
   "source": [
    "folder = nltk.data.find(path)\n",
    "corpusReader = nltk.corpus.PlaintextCorpusReader(folder, filename)\n",
    "\n",
    "# SOURCE: https://stackoverflow.com/questions/35900029/average-sentence-length-for-every-text-in-corpus-python3-nltk\n",
    "avg = sum(len(sent) for sent in corpusReader.sents()) / len(corpusReader.sents())\n",
    "print(\"Average Sentence Length: \", avg, \"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the text file: 2096\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/itudidyay/Tagalog-Word-Syllabization-Python\n",
    "# https://pypi.org/project/syllables/\n",
    "\n",
    "vowels = 'aeiou'\n",
    "consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "\n",
    "total_syllables = 0\n",
    "\n",
    "def count_syllables(text):\n",
    "    global total_syllables\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    for token in tokens:\n",
    "        for char in token:\n",
    "            if char in vowels:\n",
    "                total_syllables += 1\n",
    "        \n",
    "        # edge cases\n",
    "        if token == 'ng' or token == 'mga': # edge case ng, mga\n",
    "            total_syllables += 1\n",
    "        \n",
    "        elif (('io') in token): # edge case -io in names/surnames\n",
    "            total_syllables -= 1\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read the text file\n",
    "    with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    total_syllables = count_syllables(text)\n",
    "\n",
    "    print(f\"Total syllables in the text file: {total_syllables}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Outputs will be placed in the 'word-freq output' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Frequency\n",
      "Word                      \n",
      "ng                      61\n",
      "ang                     60\n",
      "sa                      54\n",
      "mga                     39\n",
      "na                      38\n",
      "...                    ...\n",
      "binti                    1\n",
      "pilay                    1\n",
      "8                        1\n",
      "jinky                    1\n",
      "nangangailangan          1\n",
      "\n",
      "[429 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the text file\n",
    "with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "temp_tokens = word_tokenize(text)\n",
    "text_tokens = [word for word in temp_tokens if word.isalnum()] # removes punctuation marks\n",
    "fdist = FreqDist(text_tokens)\n",
    "\n",
    "# Create a DataFrame from the frequency distribution\n",
    "df_fdist = pd.DataFrame.from_dict(fdist, orient='index', columns=['Frequency'])\n",
    "df_fdist.index.name = 'Word'\n",
    "\n",
    "# Sort the DataFrame by frequency in descending order\n",
    "df_fdist_sorted = df_fdist.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "print(df_fdist_sorted)\n",
    "\n",
    "out_path = os.getcwd() + \"/word-freq output\"\n",
    "out_filename = \"[wordfreq] \" + filename.removesuffix('_cleaned.txt') + \".csv\"\n",
    "df_fdist_sorted.to_csv(os.path.join(out_path, out_filename), encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
