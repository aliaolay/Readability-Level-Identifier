{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiled Scripts for Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> _Click 'Run All' to extract the text features of a text file._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "import syllables\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import stopwordsiso\n",
    "from stopwordsiso import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"/clean-txt/\"      # gets path to 'clean-txt' directory\n",
    "filename = input(\"Input text filename: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words:  973\n"
     ]
    }
   ],
   "source": [
    "file = open(path + filename, \"rt\")\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print(\"Number of Words: \", len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentences:  85\n"
     ]
    }
   ],
   "source": [
    "folder = nltk.data.find(path)\n",
    "corpusReader = nltk.corpus.PlaintextCorpusReader(folder, filename)\n",
    "\n",
    "print(\"Number of Sentences: \", len(corpusReader.sents()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Length:  5.216380182002022 letters\n"
     ]
    }
   ],
   "source": [
    "with open(path + \"/\" + filename, 'r') as file:\n",
    "    word_length = [len(word) for line in file for word in line.rstrip().split(\" \")]\n",
    "    word_avg = sum(word_length)/len(word_length)\n",
    "    \n",
    "print(\"Average Word Length: \", word_avg, \"letters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length:  13.823529411764707 words\n"
     ]
    }
   ],
   "source": [
    "folder = nltk.data.find(path)\n",
    "corpusReader = nltk.corpus.PlaintextCorpusReader(folder, filename)\n",
    "\n",
    "# SOURCE: https://stackoverflow.com/questions/35900029/average-sentence-length-for-every-text-in-corpus-python3-nltk\n",
    "avg = sum(len(sent) for sent in corpusReader.sents()) / len(corpusReader.sents())\n",
    "print(\"Average Sentence Length: \", avg, \"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total syllables in the text file: 2096\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/itudidyay/Tagalog-Word-Syllabization-Python\n",
    "# https://pypi.org/project/syllables/\n",
    "\n",
    "vowels = 'aeiou'\n",
    "consonants = 'bcdfghjklmnpqrstvwxyz'\n",
    "\n",
    "total_syllables = 0\n",
    "\n",
    "def count_syllables(text):\n",
    "    global total_syllables\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    for token in tokens:\n",
    "        for char in token:\n",
    "            if char in vowels:\n",
    "                total_syllables += 1\n",
    "        \n",
    "        # edge cases\n",
    "        if token == 'ng' or token == 'mga': # edge case ng, mga\n",
    "            total_syllables += 1\n",
    "        \n",
    "        elif (('io') in token): # edge case -io in names/surnames\n",
    "            total_syllables -= 1\n",
    "\n",
    "    return total_syllables\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Read the text file\n",
    "    with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    total_syllables = count_syllables(text)\n",
    "\n",
    "    print(f\"Total syllables in the text file: {total_syllables}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Outputs will be placed in the 'word-freq output' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alia\\Documents\\school\\THESIS\\Readability-Level-Identifier\\final.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alia/Documents/school/THESIS/Readability-Level-Identifier/final.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, filename), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alia/Documents/school/THESIS/Readability-Level-Identifier/final.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     text \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alia/Documents/school/THESIS/Readability-Level-Identifier/final.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39m\u001b[39mtl\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alia/Documents/school/THESIS/Readability-Level-Identifier/final.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m text_tokens \u001b[39m=\u001b[39m word_tokenize(text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alia/Documents/school/THESIS/Readability-Level-Identifier/final.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m filtered_tokens \u001b[39m=\u001b[39m [word\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m text_tokens \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words] \u001b[39m#removes stopwords\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the text file\n",
    "with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "stop_words = set(stopwords('tl'))\n",
    "\n",
    "text_tokens = word_tokenize(text)\n",
    "filtered_tokens = [word.lower() for word in text_tokens if word.lower() not in stop_words] #removes stopwords\n",
    "text_tokens = [word for word in filtered_tokens if word.isalnum()] # removes punctuation marks\n",
    "fdist = FreqDist(text_tokens)\n",
    "\n",
    "# Create a DataFrame from the frequency distribution\n",
    "df_fdist = pd.DataFrame.from_dict(fdist, orient='index', columns=['Frequency'])\n",
    "df_fdist.index.name = 'Word'\n",
    "\n",
    "# Sort the DataFrame by frequency in descending order\n",
    "df_fdist_sorted = df_fdist.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "#print(df_fdist_sorted)\n",
    "\n",
    "out_path = os.getcwd() + \"/word-freq output\"\n",
    "out_filename = \"[wordfreq] \" + filename.removesuffix('_cleaned.txt') + \".csv\"\n",
    "df_fdist_sorted.to_csv(os.path.join(out_path, out_filename), encoding='utf-8')\n",
    "\n",
    "#load in the dataframe\n",
    "df = pd.read_csv(os.path.join(out_path, out_filename), index_col=0)\n",
    "df.head(500)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10)\n",
    "wordcloud.generate(' '.join(text_tokens))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "wordcloud.to_file(out_path + \"/wordcloud/\" + filename.removesuffix('_cleaned.txt') + \".png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
