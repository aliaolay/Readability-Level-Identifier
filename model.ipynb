{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable     # https://pypi.org/project/prettytable/\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import randint\n",
    "\n",
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# https://seaborn.pydata.org/\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 19)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "text_features = pd.read_csv(path + \"/book.csv\")\n",
    "text_features_header = list(text_features.columns)\n",
    "\n",
    "text_features\n",
    "text_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table(prediction, tests):\n",
    "\n",
    "    data = []\n",
    "    i = 0\n",
    "    book_titles = tests\n",
    "\n",
    "    for test in book_titles:\n",
    "        unit = []\n",
    "        unit.append(text_features.loc[test]['Book Title'])\n",
    "        unit.append(prediction[i][0])\n",
    "        unit.append(prediction[i][1])\n",
    "        data.append(unit)\n",
    "        i += 1\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.title = 'Test Predictions'\n",
    "    table.field_names = ['Test Title', 'Min Age', 'Max Age']\n",
    "    table.align['Test Title'] = 'l'\n",
    "    \n",
    "    for row in data:\n",
    "        table.add_row(row)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_features.drop(columns=['Unnamed: 0', 'Book Title', 'MIN', 'MAX'])\n",
    "y = text_features[['MIN', 'MAX']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "# scaler here\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|                   Test Predictions                  |\n",
      "+---------------------------------+---------+---------+\n",
      "| Test Title                      | Min Age | Max Age |\n",
      "+---------------------------------+---------+---------+\n",
      "| Ang Batang Maraming Bawal       |    6    |    12   |\n",
      "| Ang Ating mga Ninuno - 1        |    3    |    10   |\n",
      "| Bandilang Pilipino (6-10)       |    6    |    10   |\n",
      "| Ang Pipit-Puso ni Emperador Wu  |    3    |    10   |\n",
      "| Plaridel 1                      |    6    |    10   |\n",
      "| Si Lupito at ang Barrio Sirkero |    8    |    16   |\n",
      "| Andres Bonifacio - 1            |    6    |    10   |\n",
      "| Mga Hiyas ng Kalayaan           |    6    |    10   |\n",
      "| Kilusang Propaganda - 1         |    6    |    10   |\n",
      "| Ang Unang Barangay (6-10)       |    6    |    10   |\n",
      "| Ang Dyip ni Mang Tomas          |    8    |    16   |\n",
      "+---------------------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=274, max_depth=17, random_state=42)\n",
    "\n",
    "multi_output_rf = MultiOutputClassifier(rf)\n",
    "multi_output_rf.fit(X_train_scaled, y_train)\n",
    "y_train_pred = multi_output_rf.predict(X_train_scaled)\n",
    "rf_pred = multi_output_rf.predict(X_test_scaled)\n",
    "\n",
    "# tried to do kfold,,, dk if appropriate\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=13)\n",
    "results = cross_val_score(multi_output_rf, X, y, cv=kf)\n",
    "\n",
    "# test pred table\n",
    "print(gen_table(rf_pred, X_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Performance Metrics\n",
      "-------------------------------------------------------\n",
      "Training Accuracy: 100.0\n",
      "Test Accuracy: 95.45454545454545\n",
      "Cross-Validation Results (Accuracy): \n",
      "Fold 1: 0.8181818181818182\n",
      "Fold 2: 0.36363636363636365\n",
      "Fold 3: 0.7272727272727273\n",
      "Fold 4: 0.6363636363636364\n",
      "Fold 5: 0.6\n",
      "Mean Accuracy: 62.909090909090914\n",
      "-------------------------------------------------------\n",
      "Classification Report for MIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.50      1.00      0.67         1\n",
      "           6       1.00      0.88      0.93         8\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.91        11\n",
      "   macro avg       0.83      0.96      0.87        11\n",
      "weighted avg       0.95      0.91      0.92        11\n",
      "\n",
      "Confusion Matrix for MIN:\n",
      "[[1 0 0]\n",
      " [1 7 0]\n",
      " [0 0 2]]\n",
      "-------------------------------------------------------\n",
      "Classification Report for MAX:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       1.00      1.00      1.00         8\n",
      "          12       1.00      1.00      1.00         1\n",
      "          16       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "Confusion Matrix for MAX:\n",
      "[[8 0 0]\n",
      " [0 1 0]\n",
      " [0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "# PERFORMANCE REPORTS\n",
    "# PERFORMANCE REPORTS\n",
    "# PERFORMANCE REPORTS\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "print('Performance Metrics')\n",
    "print('-------------------------------------------------------')\n",
    "training_accuracy = accuracy_score(y_train.values.ravel(), y_train_pred.ravel()) * 100\n",
    "print(\"Training Accuracy:\", training_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test.values.ravel(), rf_pred.ravel()) * 100\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "print(f'Cross-Validation Results (Accuracy): ')\n",
    "fold = 1\n",
    "for value in results:\n",
    "    print(f\"Fold {fold}: {value}\")\n",
    "    fold += 1\n",
    "\n",
    "# before HPT 59.272727\n",
    "# after HPT  62.909090\n",
    "print(f'Mean Accuracy: {(results.mean()) * 100}')\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "# classification report, MIN\n",
    "print(\"Classification Report for MIN:\")\n",
    "print(classification_report(y_test['MIN'], rf_pred[:, 0]))\n",
    "conf_matrix_min = confusion_matrix(y_test['MIN'], rf_pred[:, 0])\n",
    "print(\"Confusion Matrix for MIN:\")\n",
    "print(conf_matrix_min)\n",
    "\n",
    "print('-------------------------------------------------------')\n",
    "\n",
    "# classification report, MAX\n",
    "print(\"Classification Report for MAX:\")\n",
    "print(classification_report(y_test['MAX'], rf_pred[:, 1]))\n",
    "conf_matrix_max = confusion_matrix(y_test['MAX'], rf_pred[:, 1])\n",
    "print(\"Confusion Matrix for MAX:\")\n",
    "print(conf_matrix_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'estimator__max_depth': 17, 'estimator__n_estimators': 274}\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "# HYPERPARAMETER TUNING\n",
    "# HYPERPARAMETER TUNING\n",
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "\n",
    "# hyperparameter search space\n",
    "param_dist = {\n",
    "    'estimator__n_estimators': randint(50, 500),\n",
    "    'estimator__max_depth': randint(1, 20)\n",
    "}\n",
    "\n",
    "base = RandomForestClassifier()\n",
    "main = MultiOutputClassifier(base)\n",
    "\n",
    "rand_search = RandomizedSearchCV(\n",
    "    main,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=7,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# best hyperparams\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Word Count', 0.06057465744189547)\n",
      "('Sentence Count', 0.044502962783569175)\n",
      "('AVG Word Length', 0.08769177232772082)\n",
      "('AVG Sentence Length', 0.09159809780530653)\n",
      "('Total Syllables', 0.07532602165374805)\n",
      "('MONOSYLL', 0.06753635581557664)\n",
      "('POLYSYLL', 0.044765539764439366)\n",
      "('NTR', 0.0652408312424354)\n",
      "('VTR', 0.06897256645015494)\n",
      "('TTR', 0.07586138734377075)\n",
      "('Root TTR', 0.07256281736398726)\n",
      "('Corrected TTR', 0.07480755090540973)\n",
      "('BiLog TTR', 0.03675402965015751)\n",
      "('LD', 0.05597619705626397)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=274, max_depth=17, random_state=42)\n",
    "\n",
    "multi_output_rf = MultiOutputClassifier(rf)\n",
    "multi_output_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "selector = SelectFromModel(multi_output_rf.estimators_[0], threshold='mean')\n",
    "selector.fit(X_train_scaled, y_train)\n",
    "best = selector.get_support()[1:]\n",
    "\n",
    "# feature selection: RF feature importance\n",
    "feature_importances = []\n",
    "for var in multi_output_rf.estimators_:\n",
    "    feature_importances.append(var.feature_importances_)\n",
    "\n",
    "avg_feature_importance = np.mean(feature_importances, axis=0)\n",
    "\n",
    "features = text_features.columns[2:-2]\n",
    "combined = zip(features, avg_feature_importance[1:])\n",
    "for pair in list(combined):\n",
    "    print(pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
