{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "#LR libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#KNN libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#RF libraries\n",
    "# source - https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#SVM libraries\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Ensemble\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Ave. Word Length</th>\n",
       "      <th>Ave. Sentence Length</th>\n",
       "      <th>Total Syllables</th>\n",
       "      <th>Noun-Token Ratio</th>\n",
       "      <th>Verb-Token Ratio</th>\n",
       "      <th>Type-Token Ratio</th>\n",
       "      <th>Root TTR</th>\n",
       "      <th>Corrected TTR</th>\n",
       "      <th>Bilogarithmic TTR</th>\n",
       "      <th>Lexical Density</th>\n",
       "      <th>FW-Token Ratio</th>\n",
       "      <th>Age Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973</td>\n",
       "      <td>85</td>\n",
       "      <td>5.216380</td>\n",
       "      <td>13.823529</td>\n",
       "      <td>2096</td>\n",
       "      <td>0.212914</td>\n",
       "      <td>0.113438</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.324938</td>\n",
       "      <td>0.229766</td>\n",
       "      <td>0.340415</td>\n",
       "      <td>0.403141</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>937</td>\n",
       "      <td>95</td>\n",
       "      <td>5.048168</td>\n",
       "      <td>12.105263</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.171946</td>\n",
       "      <td>0.103167</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.330911</td>\n",
       "      <td>0.233990</td>\n",
       "      <td>0.342185</td>\n",
       "      <td>0.412670</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900</td>\n",
       "      <td>72</td>\n",
       "      <td>4.793478</td>\n",
       "      <td>15.097222</td>\n",
       "      <td>1844</td>\n",
       "      <td>0.136999</td>\n",
       "      <td>0.105312</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.335809</td>\n",
       "      <td>0.237453</td>\n",
       "      <td>0.343626</td>\n",
       "      <td>0.367195</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1279</td>\n",
       "      <td>97</td>\n",
       "      <td>4.959199</td>\n",
       "      <td>16.319588</td>\n",
       "      <td>2596</td>\n",
       "      <td>0.192617</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.284970</td>\n",
       "      <td>0.201504</td>\n",
       "      <td>0.328185</td>\n",
       "      <td>0.405369</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876</td>\n",
       "      <td>75</td>\n",
       "      <td>4.849498</td>\n",
       "      <td>14.053333</td>\n",
       "      <td>1824</td>\n",
       "      <td>0.195192</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.341096</td>\n",
       "      <td>0.241191</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1177</td>\n",
       "      <td>137</td>\n",
       "      <td>5.007531</td>\n",
       "      <td>10.883212</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.178177</td>\n",
       "      <td>0.104972</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.289074</td>\n",
       "      <td>0.204406</td>\n",
       "      <td>0.329475</td>\n",
       "      <td>0.381906</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1601</td>\n",
       "      <td>120</td>\n",
       "      <td>5.328449</td>\n",
       "      <td>15.816667</td>\n",
       "      <td>3610</td>\n",
       "      <td>0.175055</td>\n",
       "      <td>0.143326</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.257279</td>\n",
       "      <td>0.181924</td>\n",
       "      <td>0.319252</td>\n",
       "      <td>0.407549</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1365</td>\n",
       "      <td>132</td>\n",
       "      <td>4.945166</td>\n",
       "      <td>12.393939</td>\n",
       "      <td>2896</td>\n",
       "      <td>0.191083</td>\n",
       "      <td>0.134395</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.277615</td>\n",
       "      <td>0.196303</td>\n",
       "      <td>0.325853</td>\n",
       "      <td>0.407643</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>4.995984</td>\n",
       "      <td>12.347826</td>\n",
       "      <td>2089</td>\n",
       "      <td>0.145889</td>\n",
       "      <td>0.139699</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.327086</td>\n",
       "      <td>0.231284</td>\n",
       "      <td>0.341053</td>\n",
       "      <td>0.416446</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>552</td>\n",
       "      <td>69</td>\n",
       "      <td>4.984211</td>\n",
       "      <td>10.231884</td>\n",
       "      <td>1177</td>\n",
       "      <td>0.129851</td>\n",
       "      <td>0.129851</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.424967</td>\n",
       "      <td>0.300497</td>\n",
       "      <td>0.368494</td>\n",
       "      <td>0.374627</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word Count  Sentence Count  Ave. Word Length  Ave. Sentence Length   \n",
       "0         973              85          5.216380             13.823529  \\\n",
       "1         937              95          5.048168             12.105263   \n",
       "2         900              72          4.793478             15.097222   \n",
       "3        1279              97          4.959199             16.319588   \n",
       "4         876              75          4.849498             14.053333   \n",
       "5        1177             137          5.007531             10.883212   \n",
       "6        1601             120          5.328449             15.816667   \n",
       "7        1365             132          4.945166             12.393939   \n",
       "8         975              92          4.995984             12.347826   \n",
       "9         552              69          4.984211             10.231884   \n",
       "\n",
       "   Total Syllables  Noun-Token Ratio  Verb-Token Ratio  Type-Token Ratio   \n",
       "0             2096          0.212914          0.113438          0.009599  \\\n",
       "1             2018          0.171946          0.103167          0.009955   \n",
       "2             1844          0.136999          0.105312          0.010252   \n",
       "3             2596          0.192617          0.100000          0.007383   \n",
       "4             1824          0.195192          0.103846          0.010577   \n",
       "5             2491          0.178177          0.104972          0.007597   \n",
       "6             3610          0.175055          0.143326          0.006018   \n",
       "7             2896          0.191083          0.134395          0.007006   \n",
       "8             2089          0.145889          0.139699          0.009726   \n",
       "9             1177          0.129851          0.129851          0.016418   \n",
       "\n",
       "   Root TTR  Corrected TTR  Bilogarithmic TTR  Lexical Density   \n",
       "0  0.324938       0.229766           0.340415         0.403141  \\\n",
       "1  0.330911       0.233990           0.342185         0.412670   \n",
       "2  0.335809       0.237453           0.343626         0.367195   \n",
       "3  0.284970       0.201504           0.328185         0.405369   \n",
       "4  0.341096       0.241191           0.345171         0.388462   \n",
       "5  0.289074       0.204406           0.329475         0.381906   \n",
       "6  0.257279       0.181924           0.319252         0.407549   \n",
       "7  0.277615       0.196303           0.325853         0.407643   \n",
       "8  0.327086       0.231284           0.341053         0.416446   \n",
       "9  0.424967       0.300497           0.368494         0.374627   \n",
       "\n",
       "   FW-Token Ratio  Age Classification  \n",
       "0        0.017452                  10  \n",
       "1        0.021719                  10  \n",
       "2        0.033551                   9  \n",
       "3        0.015436                  12  \n",
       "4        0.001923                   9  \n",
       "5        0.016575                  12  \n",
       "6        0.004376                   9  \n",
       "7        0.012102                  12  \n",
       "8        0.002653                  10  \n",
       "9        0.007463                   9  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "text_features = pd.read_csv(path + \"/extracted_TRAD_LEX.csv\")\n",
    "text_features_header = [\"Word Count\", \"Sentence Count\", \"Ave. Word Length\", \"Ave. Sentence Length\", \"Total Syllables\", \"Noun-Token Ratio\",\n",
    "                        \"Verb-Token Ratio\", \"Type-Token Ratio\", \"Root TTR\", \"Corrected TTR\", \"Bilogarithmic TTR\", \"Lexical Density\",\n",
    "                        \"FW-Token Ratio\", \"Age Classification\"]\n",
    "\n",
    "text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_features[text_features_header[:-1]].values\n",
    "y = text_features[['Age Classification']].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_pred = logreg.predict(X_test_scaled)\n",
    "print(\"Predictions: \", lr_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, lr_pred)\n",
    "conf_matrix = confusion_matrix(y_test, lr_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [10 12]\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_pred = knn.predict(X_test_scaled)\n",
    "print(\"Predictions: \", knn_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, knn_pred)\n",
    "conf_matrix = confusion_matrix(y_test, knn_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [10 12]\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "print(\"Predictions: \", rf_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, rf_pred)\n",
    "conf_matrix = confusion_matrix(y_test, rf_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_pred = clf_svm.predict(X_test_scaled)\n",
    "print(\"Predictions: \", svm_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, svm_pred)\n",
    "conf_matrix = confusion_matrix(y_test, svm_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used Stacking based on this source: https://www.geeksforgeeks.org/stacking-in-machine-learning-2/\n",
    "# meta-model used: Linear Regression\n",
    "\n",
    "meta_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "lr_svm_stack = StackingClassifier(classifiers =[logreg, clf_svm], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = lr_svm_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "lr_knn_stack = StackingClassifier(classifiers =[logreg, knn], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = lr_knn_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "lr_rf_stack = StackingClassifier(classifiers =[logreg, rf], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = lr_rf_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "svm_knn_stack = StackingClassifier(classifiers =[clf_svm, knn], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = svm_knn_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 9 12]\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "svm_rf_stack = StackingClassifier(classifiers =[clf_svm, rf], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = svm_rf_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_rf_stack = StackingClassifier(classifiers =[knn, rf], meta_classifier = meta_model)\n",
    "\n",
    "model_stack = knn_rf_stack.fit(X_train_scaled, y_train)\n",
    "pred_stack = model_stack.predict(X_test_scaled)\n",
    "print(\"Predictions: \", pred_stack)\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_stack)\n",
    "conf_matrix = confusion_matrix(y_test, pred_stack)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
